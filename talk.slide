Hostnames suck, or managing EC2 servers with Ansible
20 May, 2014

Lorin Hochstein
Lead Software Engineer, SendGrid Labs
lorin.hochstein@sendgrid.com
@lhochstein

* "Try our free server monitoring!"

.image NewRelic-logo-square-RGBHEX.png 416 512

_note:_not_affiliated_with_New_Relic_


* 

.image new-relic-instructions.png 541 525

* 

.code new-relic.yml

* 

# Here's something you run into pretty quickly
# Ansible needs to know where your hosts are

    $ ansible-playbook new-relic.yml

* 

    $ ansible-playbook new-relic.yml
    PLAY [Configure server to monitor with New Relic] *****************************

    TASK: [add New Relic apt repository] ******************************************
    ok: [ec2-62-140-62-213.compute-1.amazonaws.com]
    changed: [ec2-23-76-62-66.compute-1.amazonaws.com]
    changed: [ec2-200-169-29-109.compute-1.amazonaws.com]

    TASK: [Add GPG key] ***********************************************************
    changed: [ec2-23-76-62-66.compute-1.amazonaws.com]
    changed: [ec2-200-169-29-109.compute-1.amazonaws.com]
    ok: [ec2-62-140-62-213.compute-1.amazonaws.com]

    TASK: [Install newrelic package] **********************************************
    changed: [ec2-23-76-62-66.compute-1.amazonaws.com]
    changed: [ec2-200-169-29-109.compute-1.amazonaws.com]
    ok: [ec2-62-140-62-213.compute-1.amazonaws.com]

    TASK: [Add license key] *******************************************************
    ok: [ec2-62-140-62-213.compute-1.amazonaws.com]
    changed: [ec2-200-169-29-109.compute-1.amazonaws.com]
    changed: [ec2-23-76-62-66.compute-1.amazonaws.com]

    TASK: [Start daemon] **********************************************************
    changed: [ec2-200-169-29-109.compute-1.amazonaws.com]
    ok: [ec2-62-140-62-213.compute-1.amazonaws.com]
    changed: [ec2-23-76-62-66.compute-1.amazonaws.com]

    PLAY RECAP ********************************************************************
    ec2-23-76-62-66.compute-1.amazonaws.com   : ok=5    changed=5    unreachable=0    failed=0
    ec2-23-76-62-66.compute-1.amazonaws.com   : ok=5    changed=5    unreachable=0    failed=0
    ec2-59-191-254-39.compute-1.amazonaws.com : ok=5    changed=0    unreachable=0    failed=0

* 

# Here's something you run into pretty quickly
# Ansible needs to know where your hosts are

    $ ansible-playbook new-relic.yml

    PLAY [Configure server to monitor with New Relic] ***************************** 
    skipping: no hosts matched

    PLAY RECAP ******************************************************************** 

* 

# We can also define groups

Inventory file

.code inventory-with-groups

Playbook

    - name: My playbook
      hosts: webservers
      tasks:
        ...

* 

# We can even define groups of groups

Inventory file

.code inventory-groups-of-groups

Playbook

    - name: My playbook
      hosts: appservers
      tasks:
        ...


# This isn't a good way to deal with EC2 instances
* 

Inventory file

.code inventory-ec2-static

Playbook

    - name: My playbook
      hosts: appservers
      tasks:
        ...

* NO!

* Use dynamic inventory

* 

# If an inventory file is executable, ansible will
# run it instead of examining it


    chmod +x ./my-inventory-file

* 

    $ ./my-inventory-file --list

    {
      ...,
      "webservers": [
        "foo.example.com",
        "bar.example.com"
     ],
      "dbservers" : [
        "one.example.com",
        "two.example.com",
        "three.example.com"
     ],
    ...
    }


* Batteries included: ec2.py

# The script has to respond to a --list to list all host and groups

* 

    $ ./ec2.py --list
    ...
    "i-3f4e42f6": [
      "ec2-107-33-214-218.compute-1.amazonaws.com"
    ],
    "i-b699a7ge": [
      "ec2-104-236-90-9.compute-1.amazonaws.com"
    ],
    "i-3g03c3cf": [
      "ec2-43-73-7-13.compute-1.amazonaws.com"
    ],
    ...

* 

Playbook

    - name: My playbook
      hosts: i-3f4e42f6
      tasks:
        ...

* 
Ad-hoc command

    $ ansible i-3f4e42f -m ping

    ec2-107-33-214-218.compute-1.amazonaws.com | success >> {
        "changed": false,
        "ping": "pong"
    }

# Ansible comes with a executable script called ec2.py.
# A couple of interesting things about this
# First off, it creates groups for instance ids

* 

  $ ./ec2.py --list
  ...
  "ec2": [
    "ec2-75-220-111-180.compute-1.amazonaws.com",
    "ec2-251-154-39-73.compute-1.amazonaws.com",
    "ec2-253-205-226-239.compute-1.amazonaws.com",
    "ec2-209-44-103-72.compute-1.amazonaws.com",
    "ec2-152-163-165-105.compute-1.amazonaws.com",
    ...
  ],
  "us-east-1": [
    "ec2-75-220-111-180.compute-1.amazonaws.com",
    "ec2-221-127-195-183.compute-1.amazonaws.com",
    "ec2-154-119-217-140.compute-1.amazonaws.com",
    ...
  ],
  "us-east-1b": [
    "ec2-75-220-111-180.compute-1.amazonaws.com",
    "ec2-189-19-204-147.compute-1.amazonaws.com",
    "ec2-165-131-196-230.compute-1.amazonaws.com",
  ...

* 

    $ ./ec2.py --list
    ...
    "key_mykeyname": [
      "ec2-19-245-71-94.compute-1.amazonaws.com",
      "ec2-41-205-182-83.compute-1.amazonaws.com",
      "ec2-19-78-31-83.compute-1.amazonaws.com",
      "ec2-249-124-225-162.compute-1.amazonaws.com",
    ...


* 


    $ ./ec2.py --list
    ...
    "security_group_ping": [
      "ec2-2-105-138-45.compute-1.amazonaws.com",
      "ec2-75-13-134-174.compute-1.amazonaws.com",
      "ec2-74-228-102-169.compute-1.amazonaws.com"
    ],
    "security_group_ssh": [
      "ec2-89-161-251-117.compute-1.amazonaws.com",
      "ec2-108-80-99-148.compute-1.amazonaws.com",
      "ec2-160-220-184-229.compute-1.amazonaws.com"
    ],
    ...


* 

  $ ./ec2.py --list
  ...
  "type_c1_medium": [
    "ec2-48-31-233-7.compute-1.amazonaws.com",
    "ec2-94-113-221-190.compute-1.amazonaws.com",
    "ec2-236-52-85-49.compute-1.amazonaws.com",
    "ec2-47-42-200-135.eu-west-1.compute.amazonaws.com"
  ],
  "type_c3_large": [
    "ec2-135-139-226-29.compute-1.amazonaws.com",
    "ec2-111-147-136-144.compute-1.amazonaws.com",
    "ec2-193-158-131-247.us-west-2.compute.amazonaws.com",
    "ec2-242-243-218-101.eu-west-1.compute.amazonaws.com"
  ],
  "type_t1_micro": [
    "ec2-172-90-237-244.compute-1.amazonaws.com",
    "ec2-187-184-160-248.compute-1.amazonaws.com",
    "ec2-229-65-104-88.compute-1.amazonaws.com",
    "ec2-160-219-218-205.compute-1.amazonaws.com"
  ],

* Use EC2 tags

* 

    Name=camp-devops
    env=testing
    role=queue

* 

.image ec2-tags.png 622 1075

* 

  $ ./ec2.py --list
  ...
  "tag_Name_camp-devops": [
    "ec2-54-186-152-191.us-west-2.compute.amazonaws.com"
  ],
  "tag_env_testing": [
    "ec2-54-186-152-191.us-west-2.compute.amazonaws.com",
    "ec2-173-107-203-37.compute-1.amazonaws.com"
  ],
  "tag_role_queue": [
    "ec2-54-186-152-191.us-west-2.compute.amazonaws.com",
    "ec2-187-184-160-248.compute-1.amazonaws.com"
  ]


# Most interesting is that you can do it by EC2 tags

* 

    - name: Do something to the production servers
      hosts: tag_env_production
      tasks:
        - ...


* 

    - name: Do something to the production servers
      hosts: production
      tasks:
        - ...


* 

Static inventory file

    [production:children]
    tag_env_production
* 

Static inventory file

    [production:children]
    tag_env_production

Playbook

    - name: Do something to the production servers
      hosts: production
      tasks:
        - ...

* 

Static inventory file

    [production:children]
    tag_env_production

Playbook

    - name: Do something to the production servers
      hosts: production
      tasks:
        - ...

Ansible doesn't like this

  $ ansible-playbook deploy-web-to-production.yml
  ERROR: child group is not defined: (tag_env_production)


* 

Static inventory file

    [production:children]
    tag_env_production

    [tag_env_production]
* 

Static inventory file

    [production:children]
    tag_env_production

    [tag_env_production]

Playbook

    - name: Do something to the production servers
      hosts: production
      tasks:
        - ...

Ansible is now happy

  $ ansible-playbook deploy-web-to-production.yml
  PLAY [Deploy web to production] ******************************************

* Build AMIs with Packer

* 

web-ami.json

.code packer-broken.json

* 

web.yml

    - name: Install nginx
      hosts: localhost
      tasks:
        - name: add nginx package
          apt: name=nginx
        - name: ensure service is running
          service: name=nginx stated

* 

    $ packer build web-ami.json

* 

    $ packer build web-ami.json

    ==> amazon-ebs: Creating temporary keypair: packer 53796bcc-1773-511b-cd8e-47e67e74b935
    ==> amazon-ebs: Creating temporary security group for this instance...
    ==> amazon-ebs: Authorizing SSH access on the temporary security group...
    ==> amazon-ebs: Launching a source AWS instance...
        amazon-ebs: Instance ID: i-0c80355f
    ==> amazon-ebs: Waiting for instance (i-0c80355f) to become ready...
    ==> amazon-ebs: Waiting for SSH to become available...
    ==> amazon-ebs: Connected to SSH!
    ==> amazon-ebs: Provisioning with Ansible...
        amazon-ebs: Creating Ansible staging directory...
        amazon-ebs: Creating directory: /tmp/packer-provisioner-ansible-local
        amazon-ebs: Uploading main Playbook file...
        amazon-ebs: Executing Ansible: cd /tmp/packer-provisioner-ansible-local && ansible-playbook /tmp/packer-provisioner-ansible-local/web.yml -c local -i "127.0.0.1,"
        amazon-ebs: bash: ansible-playbook: command not found
    ==> amazon-ebs: Terminating the source AWS instance...
    ==> amazon-ebs: Deleting temporary security group...
    ==> amazon-ebs: Deleting temporary keypair...

    Build 'amazon-ebs' errored: Error executing Ansible: ansible-playbook could not be found.
    Verify that it is available on the PATH after connecting to the machine.

* 

web-ami.json

.code packer.json

* 

    $ packer build web-ami.json

    ==> amazon-ebs: Creating temporary keypair: packer 5376b96a-f3bd-68d7-12cf-1b45e7feb653
    ==> amazon-ebs: Creating temporary security group for this instance...
    ==> amazon-ebs: Authorizing SSH access on the temporary security group...
    ==> amazon-ebs: Launching a source AWS instance...
        amazon-ebs: Instance ID: i-69913e3a
    ==> amazon-ebs: Waiting for instance (i-69913e3a) to become ready...
    ==> amazon-ebs: Waiting for SSH to become available...
    ==> amazon-ebs: Connected to SSH!
    ==> amazon-ebs: Provisioning with shell script: /var/folders/lc/k_jx2vhx1dj8rdl3hzlsbd1m0000gp/T/packer-shell979032617
        ...
    ==> amazon-ebs: Provisioning with Ansible...
        ...
    ==> amazon-ebs: Terminating the source AWS instance...
    ==> amazon-ebs: Deleting temporary security group...
    ==> amazon-ebs: Deleting temporary keypair...
    Build 'amazon-ebs' finished.

    ==> Builds finished. The artifacts of successful builds are:
    --> amazon-ebs: AMIs were created:

    us-east-1: ami-ae806ec6

* 

    $ ansible localhost -m ec2_ami -a "image_id=ami-ae806ec6 state=absent delete_snapshot=yes"

    localhost | success >> {
        "changed": true,
        "msg": "AMI deregister/delete operation complete"
    }

* Ansible ships with many EC2 modules

- ec2 - create, terminate, stop or start instances
- ec2_ami - create or destroy images
# - ec2_tags - create or remove tags
#- ec2_facts - gathers facts about remote hosts within ec2
# - ec2_ami_search -  Retrieve AWS AMI for a given operating system
- ec2_eip - associate an EC2 elastic IP with an instance
- ec2_vpc - configure AWS virtual private clouds
# - ec2_lc - Create or delete AWS Autoscaling Launch Configurations
# - ec2_key - maintain an ec2 key pair
- ec2_vol - create and attach a volume, return volume id and device map
# - ec2_group - maintain an ec2 VPC security group.
# - ec2_elb_lb - Creates or destroys Amazon ELB
- ec2_snapshot - creates a snapshot from an existing volume
# - ec2_metric_alarm - Create/update or delete AWS Cloudwatch ‘metric alarms’
# - ec2_scaling_policy - Create or delete AWS scaling policies for Autoscaling groups
- ec2_vpc - configure AWS virtual private clouds
- ec2_asg - Create or delete AWS Autoscaling Groups
- ec2_elb - De-registers or registers instances from EC2 ELBs
- route53 - add or delete entries in Amazons Route53 DNS service


* Takeaways

- Use dynamic inventory
- Use EC2 tags to define Ansible host groups
- Specify better group names by editing static inventory file
- Use Packer for creating AMIs with Ansible


* Slides are on Github

.link https://github.com/lorin/camp-devops-talk
.link http://go-talks.appspot.com/github.com/lorin/camp-devops-talk/talk.slide
